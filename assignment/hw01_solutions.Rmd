---
title: 'USP654 Fall 2017 HW1 Solutions'
output: html_document
---

```{r setup, include=F, warning=F, message=F}
options(knitr.kable.NA = '')
options(digits = 2)

require(captioner)
figures <- captioner()
tables <- captioner(prefix = "Table")
```

# Correlation and Ordinary Least Squares Regression

> 1. [36 points] Using [the provided california Transit Oriented Development (TOD) dataset](californiatod.csv), answer the following questions. Assuming the dataset represents the entire TOD projects in California (population) when the dataset was collected, so be sure to consider that fact in your responses. `transit` is the share of transit trips among all households living in a property while density is the development density in dwelling units/acre. 

>    a. [4 points] Report the mean & standard deviation of transit usage (`transit` variable) and density. Calculate the Pearson correlation coefficient (`rxy`) between transit usage (`transit` variable) and density. Use any formula that’s convenient, but only use built in functions (e.g. cor() in R or correlations in SPSS) to check your work. Briefly interpret the result, including a supporting plot if you think it helps.

Mean $\bar{x} = \frac{\sum_i x_i}{n}$, standard deviation $\sigma = \sqrt{\frac{\sum_i {(x_i - \bar{x})^2}}{(n - 1)}}$, and Pearson's correlation $r_{xy}= \frac{\sum_i{(x_i - \bar{x})(y_i - \bar{y})}}{\sqrt{\sum_i(x_i - \bar{x})^2} \sqrt{\sum_i(y_i - \bar{y})^2}}$. `r tables("desc1", display="cite")` shows the results.
```{r, message=F, warning=F}
require(tidyverse)
californiatod <- read_csv("californiatod.csv")
y <- californiatod$transit
x <- californiatod$density

x_bar <- sum(x)/length(x)
x_sd <- sqrt(sum((x - x_bar)^2)/(length(x) - 1))
y_bar <- sum(y)/length(y)
y_sd <- sqrt(sum((y - y_bar)^2)/(length(y) - 1))

r_xy <- sum((x - x_bar)*(y - y_bar))/(sqrt(sum((x - x_bar)^2)) * sqrt(sum((y - y_bar)^2)))

tribble(
  ~Measure, ~density,  ~transit,
  "mean", x_bar, y_bar,
  "sd",   x_sd,  y_sd,
  "correlation", r_xy, r_xy
) %>% 
  knitr::kable(caption=tables("desc1", "Descriptive Statistics of transit and density"))
```

We can verify our results with the built-in R functions `mean`, `sd`, and `cor`.

Since the transit variable is bounded between 0 and 1, it has much smaller mean and standard deviation than density. There is very weak correlation between transit and density as the Pearson's correlation $r=0.03$, very close to 0.
    
>    b. [4 points] Now explain in words and functional formula(e) how you might model the relationship between transit usage and density  as a linear regression model. Be sure to identify and justify your assignment of variables, and explain the assumptions of your population regression function.

The transportation planning literature has only documented the relationship between transit usage and built environment (of which density is a measure), in which higher density would promote transit usage. Based on this research, it is of interest to model transit usage as a function of density in an OLS regression: $\text{Transit}_i = \beta_0 + \beta_1 \text{density}_i + \epsilon_i$. The assumption for the regression is that the error term $\epsilon_i$ follows an independent and identical Normal distribution: $\epsilon_i \sim N(0, \sigma^2)$.

>    c. [4 points] Use equations (or matrix algebra, if you must!) to calculate ordinary least squares (OLS) solutions for $\beta_0$ and $\beta_1$ in your regression function (again, you may use built-in functions like lm() to check your work, but obtain the results using simple algebraic functions like sum()). Interpret the values obtained.

The formula for OLS solutions of the coefficients are: $\beta_1 = \frac{ \sum{x_iy_i} - \frac{1}{n}\sum{x_i}\sum{y_i} }{ \sum{x_i^2} - \frac{1}{n}(\sum{x_i})^2 }$ , and $\beta_0 = \overline{y} - \beta_1\overline{x}$.

Using R for the calcuation following the formulae:
```{r, message=F, warning=F}
n <- length(y)
beta1 <- (sum(x*y) - 1/n * sum(x) * sum(y))/(sum(x^2) - 1/n * (sum(x))^2)
beta0 <- y_bar - beta1 * x_bar
```

and we have $\beta_0=$ `r beta0` and $\beta_1=$ `r beta1`, which gives the same results as `lm(y ~ x)`. Note that since we are running regression with population data, there is no need to denote our coefficient estimates as $\hat{\beta_0}$ and $\hat{\beta_1}$.
    
>    d. [4 points] Calculate the conditional means of Y for each value of X=x in the population. How are these results related to your population regression function?

The conditional means of Y can be calculated with equation $E(y|x) = \beta_0 + \beta_1x$ and `r tables("Eyx1", display="cite")` shows the conditional means.
```{r, message=F, warning=F}
Ey <- beta0 + beta1 * x

tibble(x=x, `E(y|x)`=Ey) %>% 
  head() %>% 
  knitr::kable(caption=tables("Eyx1", "Conditional Means E(y|x)"))
```
    
>    e. [4 points] Plot (R, SPSS, or another method) the following clearly:
>    
>	     - XY scatterplot of the data
>	     - Conditional means of Y given X=x for all values of X
>	     - Your population regression line (PRL)

```{r, warning=F, message=F, fig.cap=figures("Eyx1", "Conditional means E(y|x)")}
ggplot(californiatod) + 
  geom_point(aes(x=density, y=transit), alpha = 0.3) +
  geom_point(aes(x=x, y=Ey)) +
  geom_abline(slope=beta1, intercept=beta0)
```

`r figures("Eyx1", display = "cite")` shows the scatter plot of density and transit, with conditional means and population regression line superimposed.

>    f. [4 points] Explain the key features of your plot in e), keeping in mind this is a population regression! For one value of X, explain precisely how each of the Y|X values relates to the PRL. Feel free to sketch on a copy of the plot to make your points clear.

There is no strong pattern in the scatter plot between density and transit, corraborating the weak correlation between the two. The conditional means all line up on the population regression line.

>    g. [4 points] Use equations to calculate and then interpret (making reference to your plot if useful).
>     - The sum of squared residuals (SSR)
>     - The total sum of squares (TSS)
>     - The coefficient of determination (R2)

SSR = $\sum_i{(y_i - \hat{y_i})^2} = \sum_i{(y_i - \beta_0 + \beta_1x_i)^2}$,

$\text{TSS} = \sum_i{(y_i - \bar{y})^2}$, and

$\text{R}^2 = \frac{MSS}{TSS} = 1 - \frac{SSR}{TSS}$
```{r, message=F, warning=F}
SSR <- sum((y - beta0 - beta1 * x)^2)
TSS <- sum((y - y_bar)^2)
R2 <- 1 - SSR/TSS

tribble(
  ~SSR, ~TSS, ~R2,
  SSR, TSS, R2
) %>% knitr::kable()
```

We can verify $R^2$ with R command `summary(lm(y ~ x))$r.squared`.

>    h. [4 points] Use the solved PRL to predict the value of $Y$ for an $X$ that does not appear in the data. Write out the equation and solution.

For any `x`, the equation for predicting from PRL is the same: $\hat{y} = \beta_0 + \beta_1x$. Pick $x = 11.0$, which does not appear in the data, $\hat{y}=\beta_0 + \beta_1*11.0$ = `r beta0 + beta1 * 11.0`. However, be aware of predicting $y$ for $x$ that far out of the range of the data. For example, it may not be a good practice to use our equation to predict for $x=100$. 

>    i. [4 points] Make a case for the inclusion of two additional explanatory/control variables you might include to better explain transit use (or density, if it is your dependent variable of choice). Describe your hypothesis of effect direction of the new variables, and how you would operationalize the variables (e.g. coding them as dummy variables).

Two variables that are potentially useful in explaining transit usage are transit service frequency and accessibility to destinations by transit. Both should affect transit use positively: higher transit frequency increases transit use and better transit accessibility increases transit use too. Both can be numeric variables, for example, headway between trains and number of jobs reachable within 30 minute ride.
	  
> 2. Repeat (1) with your own dataset of a random sample. First make it clear whether you are working with a population or a sample. If your dataset is for a population, draw randomly from the population (with `sample_n()` function in R and `Data/Select Cases` in SPSS) to create a random sample of at least 10 observations. For this section, you may use built-in software functions (e.g. cor() and lm() in R, or correlations and regression in SPSS) for each part. No need to write out the equations again. For each sub-question in (1), interpret the results in term of sample regression. For part (e), plot the sample regression lines (SRL) on the plot. In addition to repeating (a)-(h) above, additionally answer the following.
> [a-h, 4 points each]
	
For Question 2, I'm using a random sample of 100 single family residence (sfr) from [the Portland tax lot sample data](taxlot_sample.csv). I am particularly interested in how the size of a house (BLDGSQFT) affects its price (TOTALVALUE), so I assign TOTALVAL as my dependent variable and BLDGSQFT the independent variable.

```{r, warning=F, message=F}
require(tidyverse)
taxlot_sample_all <- read_csv("taxlot_sample.csv")
set.seed(1)
sfr_sample <- taxlot_sample_all %>% 
  filter(sfr==1) %>% 
  sample_n(size=100)
```

I start off with visualization and descriptives. `r figures("scattplot_sfr", display="cite")` shows a scatter plot between BLDGSQFT and TOTALVAL, while `r tables("desc_sfr", display="cite")` presents the descriptive statistics. The value of a house goes up as its size increases, although there is larger variation in the value for larger houses, as shown by the wider spread of the data points toward the right end of the x-axis (`r figures("scattplot_sfr", display="cite")`). The correlation between the two is `r cor(sfr_sample[, c("BLDGSQFT", "TOTALVAL")])[1, 2]`, indicating a strong correlation between house size and price as expected.

```{r, fig.cap=figures("scattplot_sfr", "Scatter Plot of building sqft and total housing value")}
ggplot(sfr_sample, aes(x=BLDGSQFT, y=TOTALVAL)) + 
  geom_point() + scale_y_continuous(labels=scales::dollar) +
  geom_smooth(method = "lm", se=FALSE)

library(devtools)
if (!require(tidytable1))
  devtools::install_github("cities-lab/tidytable1")

sfr_sample %>%
  select(BLDGSQFT, TOTALVAL) %>% 
  tidytable1::tidytable1(calc_cols = c()) %>% 
  knitr::kable(caption=tables("desc_sfr", "Descriptive Statistics"))
```

Using `lm` for regression this time, the result of the OLS regression is shown in `r tables("fit_val_sqft", display="cite")`

```{r}
library(huxtable)
model1 <- lm(TOTALVAL ~ BLDGSQFT, data=sfr_sample)

model1 %>% 
  huxreg() %>% 
  set_caption(tables("fit_val_sqft", "OLS Regression of Total Housing Value"))
```

Conditional means E(y|x) can be computed similar to Question 1. `r tables("Eyx2", display="cite")` shows the first 6 results of the conditional means:
```{r}
coefs <- coef(model1)
x <- sfr_sample$BLDGSQFT
Ey <- coefs["(Intercept)"] + coefs["BLDGSQFT"] * x

tibble(x=x, `E(y|x)`=Ey) %>% 
  head() %>% 
  knitr::kable(caption=tables("Eyx2", "Conditional Means E(y|x)"))
```

We can compute SSR, TSS and R2 from the regression results:

```{r}
n <- nrow(sfr_sample)
SSR <- resid(model1)^2 %>% sum
TSS <- var(sfr_sample$TOTALVAL) * (n - 1)
R2 <- 1 - SSR/TSS

tribble(
  ~SSR, ~TSS, ~R2,
  SSR, TSS, R2
) %>% knitr::kable()
```

>    j. [4 points] Interpret the significance of:
>	     - the model;
>	     - the estimate of $\beta_0$ and $\beta_1$.

The model is significant as the p	value is close to 0 and both intercept and the coefficient for BLDGSQFT are significant at 0.1% signficance level.

>    k. [4 points] Construct 95% confidence intervals for each $\beta$ in your SRL estimates. Interpret the range and its statistical meaning.

The coefficient intervals for both coefficients are in `r tables("ci_coef", display="cite")`. If the model assumptions hold, we are 95% certain that the slope of the PRL in the range [163, 226], or we can be 95% confident that the average housing price increases between 163 and 226 dollars for every one sqft increase in housing floor area (BLDGSQFT).

```{r}
model1 %>% confint %>%
  knitr::kable(caption=tables("ci_coef", "95% Confidential Intervals of the estimated coefficients"))
```
	  
>    k. [2 points for additional variable discussion + 6 points for estimating models and conducting tests] For question 1.i, in addition to describing your hypothesis of effect direction of the new variables, and how you would operationalize the variables (e.g. coding them as dummy variables), run regression models with the two additional variables and conduct hypothesis tests whether the full model with additional variables are statistically better than the restricted model you estimated earlier.

Two additional variables of interest are year built (YEARBUILT) and lot size (GIS_ACRES). I would expect newer houses are more expensive on average (as YEARBUILD increases, price decreases) and houses on larger lot are more expensive (although it may be highly correlated with BLDGSQFT), everything else being the same. Since both variables are numeric variables, they can enter the regression model as independent variables without special handling. `r tables("fit_model123", display="cite")` shows the estimation results of all three models. As expected, the coefficient for year built is negative, with old buildings depreciating about $1,630 every year. However, the GIS_ACRES coefficient is not statistically significant, that is, after controling for BLDGSQFT and YEARBUILT, the lot size does not seem to affect housing price.

```{r}
model2 <- lm(TOTALVAL ~ BLDGSQFT + YEARBUILT, data=sfr_sample)
model3 <- lm(TOTALVAL ~ BLDGSQFT + YEARBUILT + GIS_ACRES, data=sfr_sample)

huxreg(model1, model2, model3) %>% 
  set_caption(tables("fit_model123", "OLS Regression of Total Housing Value"))
```	  

We can run F tests to compare the three models. `r tables("anova_model123", display="cite")` shows the results of the F tests. Model (2) adds YEARBUILT to model (1), which increases the R2 from 0.51 to 0.619 and the F test indicates model (2) is significant better model than model (1) with p-value = 0.000. However, with GIS_ACRES added to model (2), model (3) has the same R2 and the F test indicates that there is no evidence model (3) is significantly better than model (2) at the 5% significance level.

```{r}
anova(model1, model2, model3) %>% 
  mutate(Model=c("(1)", "(2)", "(3)")) %>% 
  knitr::kable(caption=tables("anova_model123", "ANOVA between the three models"))
```
	  
> 3. [12 points] Choose ONE of the articles included in the folder to read. In 2-3 paragraphs, briefly describe the primary research question(s), research hypotheses, and experimental design of the study; then, choose ONE of the presented models and interpret the results. Include in your interpretation discussions of significance and effect size. Also include your own critique in terms of the modeling and interpretation. Make a case for one additional continuous explanatory/control variable and one discrete/dummy variable the authors could perhaps have included. 
>
>    Please note the below points for your chosen study (Both paper available on D2L):
> 
>    - [Baskin et al. (Physical Activity Correlates)](https://link.springer.com/article/10.1007%2Fs12160-012-9437-7) - Paper states that standardized coefficients listed in Tables 2 & 3, but they are actually unstandardized (i.e. in original variable units). Also ignore typo where states “logistic regression” was run. All models are in fact classical linear regression.
>    - [Lund (Pedestrian environments & community)](http://journals.sagepub.com/doi/abs/10.1177/0739456X0202100307) - Don’t worry about “Hierarchical Linear Model” (HLM); this is just a term for adding variables to a linear regression in groups and doesn’t impact the estimation or interpretation of results.
