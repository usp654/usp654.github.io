---
title: 'USP654 Lab 7: Nonlinear Relationship'
date: "11/06/2017"
output: 
  html_document:
    toc: true
---

```{r setup, include=F}
knitr::opts_chunk$set(message=FALSE, warning=F, echo=TRUE)
options(width = 2000)
options(repos="https://cran.rstudio.com")
```

## Testing Differences in Means Among the Included Groups with Interactions

```{r}
require(tidyverse)

# create an artificial housework chore dataset
chores <- mtcars %>% select(hours=mpg, married=vs, women=am)
rownames(chores) <- NULL

lm(hours ~ married * women, data=chores) %>% 
  summary
```

1. Redefine reference category 
```{r}
chores <- chores %>% mutate(unmarried = !married, men=!women)

lm(hours ~ unmarried * women, data=chores) %>% 
  summary

lm(hours ~ married * men, data=chores) %>% 
  summary

lm(hours ~ unmarried * men, data=chores) %>% 
  summary

```

**Q: Do married women and men spend similar hours on housework chores?**

2. Partial F test:

- $H_0: \beta_2 + \beta_2=0$
- $H_A: \beta_2 + \beta_2 \ne 0$

```{r}
car::lht(lm(hours ~ married*women, data=chores), "women + married:women = 0")
```

2. linear combination of coefficients

- The point estimate is $\hat{\beta_2} + \hat{\beta_3}$
- In this case, our linear combination involves the sum rather than the difference between two coefficients, and the formula for estimating the standard error of the sum of two coefficients is: $$\sqrt{\hat{\sigma^2_{\hat{\beta_2}}} + \hat{\sigma^2_{\hat{\beta_3}}} + 2\hat{cov}_{\hat{\beta_2}\hat{\beta_3}}}$$

- $H_0: \beta_2 + \beta_2=0$
- $H_A: \beta_2 + \beta_2 \ne 0$

```{r}
fit1 <- lm(hours ~ married*women, data=chores)
beta2 <- coef(fit1)["women"]
beta3 <- coef(fit1)["married:women"]

betas_vcov <- vcov(fit1)
se <- sqrt(betas_vcov["women", "women"] + betas_vcov["married:women", "married:women"] + 2 * betas_vcov["women", "married:women"])

(t_stat <- (beta2 + beta3)/se)

## Degrees of Freedom
dof <- fit1$df.residual

## compare t_stat to critical t-value
(t_crit <- qt(0.025, df=dof, lower.tail = F))
## OR find the corresponding p-value
(p_val <- 2 * pt(t_stat, lower.tail = F, df=dof))

```

**Task**: Does marital status change number of hours women spending on housework chores?

## Nonlinear Relationship

[Download california.csv](californiatod.csv)

If you suspect nonlinear relationship between two variables, it is always a good idea to to plot your data:

```{r, results="asis"}

require(tidyverse)
californiatod <- read_csv("californiatod.csv")

require(ggplot2)
ggplot(data=californiatod, aes(x=density, y=houseval)) + geom_point() + geom_smooth()
```

## Add nonlinear terms

In R, you can easily create nonlinear terms by indicating the transformation you want with the corresponding functions:

```{r}
huxtable::huxreg(
  lm(houseval ~ density, data=californiatod),
  lm(houseval ~ density + I(density^2), data=californiatod),
  lm(houseval ~ log(density), data=californiatod),
  lm(log(houseval) ~ density, data=californiatod),
  lm(log(houseval) ~ log(density), data=californiatod)
  )
```

## Partial F test on the nonlinear term

```{r}
anova(
  lm(houseval ~ density, data=californiatod),
  lm(houseval ~ density + I(density^2), data=californiatod)
)
```

To be on the safe side, enclose your tranformation in an `I()` function: `lm(houseval ~ density + I(density^2), data=californiatod)`. This is not necessary for log transformation.

## Tasks

1. Does marital status change number of hours women spending on housework chores?
2. Select a few of numeric variables in your own dataset:
    - Plot them in scatter plots;
    - Is there a reason that you suspect there may be nonlinear relationship between the numeric variables, based on theory or observation from your plots?
    - Experiment with nonlinear terms in your regression model;
    - Is there any indication that nonlinear term produce a better model fit? Why?
